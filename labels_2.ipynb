{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 코랩에서 Chrome과 ChromeDriver 설치\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "# 필요한 패키지 설치\n",
        "!pip install selenium pandas\n",
        "\n",
        "# 환경 변수 설정\n",
        "import os\n",
        "os.environ['PATH'] += ':/usr/bin'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOe89rMOnJp4",
        "outputId": "a6437c62-bbd9-44a7-ab5b-2f742d751024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [1\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [C\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,056 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,024 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,253 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,532 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,747 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,561 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,340 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,703 kB]\n",
            "Fetched 30.6 MB in 3s (9,252 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 libudev1 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n",
            "  squashfs-tools systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 8 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 30.3 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.16 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.67.1+22.04 [27.8 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.3 MB in 1s (25.4 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 126319 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126519 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.67.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.67.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.16) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.67.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 126748 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.16) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.33.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: urllib3~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.4.26 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.6.15)\n",
            "Requirement already satisfied: typing_extensions~=4.13.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "62n8FCuWlheM",
        "outputId": "8fac5970-71cd-4246-9b1f-ad7c4c409efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.33.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.4.26 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.6.15)\n",
            "Requirement already satisfied: typing_extensions~=4.13.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.1.0 webdriver-manager-4.0.2\n",
            "=== 서울특별시 싱크홀 데이터 크롤링 시작 ===\n",
            "브라우저 시작 중...\n",
            "페이지 로드 완료\n",
            "테이블 로딩 대기 중...\n",
            "서울특별시 필터링 적용 중...\n",
            "페이지 1 크롤링 중...\n",
            "페이지 1에서 10개 데이터 수집\n",
            "페이지 2 크롤링 중...\n",
            "페이지 2에서 10개 데이터 수집\n",
            "페이지 3 크롤링 중...\n",
            "페이지 3에서 10개 데이터 수집\n",
            "페이지 4 크롤링 중...\n",
            "페이지 4에서 10개 데이터 수집\n",
            "페이지 5 크롤링 중...\n",
            "페이지 5에서 10개 데이터 수집\n",
            "페이지 6 크롤링 중...\n",
            "페이지 6에서 10개 데이터 수집\n",
            "페이지 7 크롤링 중...\n",
            "페이지 7에서 10개 데이터 수집\n",
            "페이지 8 크롤링 중...\n",
            "페이지 8에서 10개 데이터 수집\n",
            "페이지 9 크롤링 중...\n",
            "페이지 9에서 10개 데이터 수집\n",
            "페이지 10 크롤링 중...\n",
            "페이지 10에서 10개 데이터 수집\n",
            "페이지 11 크롤링 중...\n",
            "페이지 11에서 10개 데이터 수집\n",
            "페이지 12 크롤링 중...\n",
            "페이지 12에서 10개 데이터 수집\n",
            "마지막 페이지 도달\n",
            "\n",
            "=== 크롤링 완료 ===\n",
            "총 120개의 서울특별시 싱크홀 데이터 수집 완료\n",
            "총 12페이지 처리\n",
            "\n",
            "=== 데이터 미리보기 ===\n",
            "      id             acc_date                  acc_loc acc_reason width  \\\n",
            "0  10110  2025-03-24 오전 00:00  서울특별시 강동구 명일동 명일동 216-9         기타    18   \n",
            "1  10010  2025-03-17 오전 00:00    서울특별시 송파구 마천동 211-142         기타     1   \n",
            "2   9810  2025-03-05 오전 00:00     서울특별시 서대문구 북아현동 1017     하수관 손상     1   \n",
            "3   9310  2025-01-17 오전 00:00    서울특별시 강서구 화곡동 1117-13         기타   0.3   \n",
            "4   9110  2025-01-16 오전 00:00     서울특별시 강북구 미아동 793-43     하수관 손상     1   \n",
            "\n",
            "  length depth geo_feat                       recovery_method  \n",
            "0     20    20       기타                        사고원인 조사 후 복구예정  \n",
            "1    0.5   1.4       기타  송파구 치수과 지하매설물 및 하수관로 이상여부 확인 후 복구 완료  \n",
            "2    0.7   1.8      미기재                                  도로포장  \n",
            "3    0.3   0.3       기타         하수관로 및 전력관로 등 지하매설물 점검 및 복구조치  \n",
            "4      1   0.6      미기재                            굴착 후 임시 복구  \n",
            "\n",
            "=== 수집된 주소 목록 (처음 10개) ===\n",
            "1. 서울특별시 강동구 명일동 명일동 216-9\n",
            "2. 서울특별시 송파구 마천동 211-142\n",
            "3. 서울특별시 서대문구 북아현동 1017\n",
            "4. 서울특별시 강서구 화곡동 1117-13\n",
            "5. 서울특별시 강북구 미아동 793-43\n",
            "6. 서울특별시 서대문구 연희동 446-92\n",
            "7. 서울특별시 동대문구 답십리동 111\n",
            "8. 서울특별시 노원구 상계동 626\n",
            "9. 서울특별시 성동구 용답동 63-3\n",
            "10. 서울특별시 종로구 효제동 291-9\n",
            "\n",
            "파일 저장 완료: seoul_sinkhole_data.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f2f1aa07-268d-4754-b156-6f5a1a0841bd\", \"seoul_sinkhole_data.csv\", 21803)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "브라우저 종료 완료\n"
          ]
        }
      ],
      "source": [
        "# 코랩용 크롤링 코드 (수정 버전)\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "import time\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def crawl_seoul_sinkhole_colab():\n",
        "    # Chrome 옵션 설정\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    chrome_options.add_argument('--disable-gpu')\n",
        "    chrome_options.add_argument('--window-size=1920,1080')\n",
        "    chrome_options.add_argument('--disable-extensions')\n",
        "    chrome_options.add_argument('--disable-plugins')\n",
        "    chrome_options.add_argument('--disable-images')\n",
        "    chrome_options.add_argument('--remote-debugging-port=9222')\n",
        "\n",
        "    # 수정된 WebDriver 생성 방법\n",
        "    try:\n",
        "        # 방법 1: Service 객체 사용 (권장)\n",
        "        service = Service('/usr/bin/chromedriver')\n",
        "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "    except:\n",
        "        try:\n",
        "            # 방법 2: 직접 경로 없이 생성\n",
        "            driver = webdriver.Chrome(options=chrome_options)\n",
        "        except:\n",
        "            # 방법 3: 환경변수 설정 후 생성\n",
        "            os.environ['PATH'] += ':/usr/bin'\n",
        "            driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    try:\n",
        "        print(\"브라우저 시작 중...\")\n",
        "\n",
        "        # 페이지 로드\n",
        "        url = \"https://sciencesay.shinyapps.io/sinkhole/\"\n",
        "        driver.get(url)\n",
        "        print(\"페이지 로드 완료\")\n",
        "\n",
        "        # 페이지 로딩 대기\n",
        "        wait = WebDriverWait(driver, 20)\n",
        "\n",
        "        # 테이블이 로드될 때까지 대기\n",
        "        print(\"테이블 로딩 대기 중...\")\n",
        "        wait.until(EC.presence_of_element_located((By.ID, \"DataTables_Table_0\")))\n",
        "\n",
        "        # 서울특별시 필터링 적용\n",
        "        print(\"서울특별시 필터링 적용 중...\")\n",
        "        search_box = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"DataTables_Table_0_filter\"]/label/input')))\n",
        "        search_box.clear()\n",
        "        search_box.send_keys(\"서울특별시\")\n",
        "        time.sleep(3)\n",
        "\n",
        "        # 데이터 저장 리스트\n",
        "        all_data = []\n",
        "        page_num = 1\n",
        "        max_pages = 50  # 무한루프 방지\n",
        "\n",
        "        while page_num <= max_pages:\n",
        "            print(f\"페이지 {page_num} 크롤링 중...\")\n",
        "\n",
        "            try:\n",
        "                # 현재 페이지의 테이블 행들 가져오기\n",
        "                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#DataTables_Table_0 tbody tr\")))\n",
        "                rows = driver.find_elements(By.CSS_SELECTOR, \"#DataTables_Table_0 tbody tr\")\n",
        "\n",
        "                # 각 행의 데이터 추출\n",
        "                page_data_count = 0\n",
        "                for row in rows:\n",
        "                    try:\n",
        "                        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
        "                        if cells and len(cells) >= 9:\n",
        "                            row_data = {\n",
        "                                'id': cells[0].text,\n",
        "                                'acc_date': cells[1].text,\n",
        "                                'acc_loc': cells[2].text,\n",
        "                                'acc_reason': cells[3].text,\n",
        "                                'width': cells[4].text,\n",
        "                                'length': cells[5].text,\n",
        "                                'depth': cells[6].text,\n",
        "                                'geo_feat': cells[7].text,\n",
        "                                'recovery_method': cells[8].text\n",
        "                            }\n",
        "                            all_data.append(row_data)\n",
        "                            page_data_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"행 처리 중 오류: {e}\")\n",
        "                        continue\n",
        "\n",
        "                print(f\"페이지 {page_num}에서 {page_data_count}개 데이터 수집\")\n",
        "\n",
        "                # 다음 페이지 버튼 확인\n",
        "                next_button = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"DataTables_Table_0_next\"]')))\n",
        "\n",
        "                # 다음 페이지가 비활성화되어 있으면 종료\n",
        "                if \"disabled\" in next_button.get_attribute(\"class\"):\n",
        "                    print(\"마지막 페이지 도달\")\n",
        "                    break\n",
        "\n",
        "                # 다음 페이지로 이동\n",
        "                driver.execute_script(\"arguments[0].click();\", next_button)\n",
        "                time.sleep(3)\n",
        "                page_num += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"페이지 {page_num} 처리 중 오류: {e}\")\n",
        "                break\n",
        "\n",
        "        # DataFrame으로 변환\n",
        "        df = pd.DataFrame(all_data)\n",
        "\n",
        "        # 결과 출력\n",
        "        print(f\"\\n=== 크롤링 완료 ===\")\n",
        "        print(f\"총 {len(df)}개의 서울특별시 싱크홀 데이터 수집 완료\")\n",
        "        print(f\"총 {page_num}페이지 처리\")\n",
        "\n",
        "        if len(df) > 0:\n",
        "            print(\"\\n=== 데이터 미리보기 ===\")\n",
        "            print(df.head())\n",
        "\n",
        "            # 주소만 추출해서 보기\n",
        "            print(\"\\n=== 수집된 주소 목록 (처음 10개) ===\")\n",
        "            addresses = df['acc_loc'].tolist()\n",
        "            for i, addr in enumerate(addresses[:10], 1):\n",
        "                print(f\"{i}. {addr}\")\n",
        "\n",
        "            # CSV 파일로 저장\n",
        "            df.to_csv('seoul_sinkhole_data.csv', index=False, encoding='utf-8-sig')\n",
        "            print(f\"\\n파일 저장 완료: seoul_sinkhole_data.csv\")\n",
        "\n",
        "            # 파일 다운로드를 위한 코드 (코랩용)\n",
        "            from google.colab import files\n",
        "            files.download('seoul_sinkhole_data.csv')\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"크롤링 중 오류 발생: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "    finally:\n",
        "        driver.quit()\n",
        "        print(\"브라우저 종료 완료\")\n",
        "\n",
        "# 실행\n",
        "print(\"=== 서울특별시 싱크홀 데이터 크롤링 시작 ===\")\n",
        "data = crawl_seoul_sinkhole_colab()"
      ]
    }
  ]
}